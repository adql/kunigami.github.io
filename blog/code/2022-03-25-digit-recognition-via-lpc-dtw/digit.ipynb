{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c4c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "from fastdtw import fastdtw\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import pydub\n",
    "import noisereduce as nr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dad412",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "Each set has speech corresponding to the pronounciation of digits from 0 to 9. The training data has multiple sets, while the test data as a single set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b709bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumes all sample rates are the same\n",
    "sample_rate = None\n",
    "    \n",
    "test_cnt = 2\n",
    "dig_cnt = 10\n",
    "\n",
    "train = [None]*test_cnt\n",
    "for t in range(test_cnt):\n",
    "    train[t] = [None]*dig_cnt\n",
    "    for i in range(dig_cnt):\n",
    "        filename = f'base/{t}/{i}.wav'\n",
    "        [instance_sample_rate, pcm_data] = scipy.io.wavfile.read(filename)\n",
    "        pcm_data = np.array(pcm_data) / np.max(pcm_data)\n",
    "        if sample_rate is None:\n",
    "            sample_rate = instance_sample_rate\n",
    "        assert sample_rate == instance_sample_rate\n",
    "\n",
    "        train[t][i] = pcm_data\n",
    "\n",
    "test = [None]*10\n",
    "for i in range(10):\n",
    "    filename = f'test1/{i}.wav'\n",
    "    [instance_sample_rate, pcm_data] = scipy.io.wavfile.read(filename)\n",
    "    pcm_data = np.array(pcm_data) / np.max(pcm_data)\n",
    "    if sample_rate is None:\n",
    "        sample_rate = instance_sample_rate\n",
    "    assert sample_rate == instance_sample_rate\n",
    "        \n",
    "    test[i] = pcm_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a813cced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common functions used by multiple cells\n",
    "\n",
    "overlap_pct = 0.4\n",
    "window_ms = 15\n",
    "\n",
    "def get_window():\n",
    "    sym = False # periodic\n",
    "    window_size = floor(window_ms/1000*sample_rate)\n",
    "    return hann(window_size, sym)\n",
    "\n",
    "def create_overlapping_blocks(x, w):\n",
    "    n = len(x)\n",
    "    nw = len(w)\n",
    "    step = floor(nw * (1 - overlap_pct))\n",
    "    nb = floor((n - nw) / step) + 1\n",
    "\n",
    "    B = np.zeros((nb, nw))\n",
    "\n",
    "    for i in range(nb):\n",
    "        offset = i * step\n",
    "        B[i, :] = w * x[offset : nw + offset]\n",
    "    \n",
    "    return B\n",
    "\n",
    "def plot_line(ax, ys, marks):\n",
    "    xs = np.array(range(len(ys))) / instance_sample_rate * 1000\n",
    "    for m in marks:\n",
    "        mt = m / instance_sample_rate * 1000\n",
    "        ax.axvline(mt, color='red')\n",
    "    ax.plot(xs, ys)\n",
    "\n",
    "def transform_data(train, test, tr):\n",
    "    dig_cnt = len(test)\n",
    "    tr_train = [0]*len(train)\n",
    "    for t in range(len(train)):\n",
    "        tr_train[t] = [None]*dig_cnt\n",
    "        for i in range(dig_cnt):\n",
    "            tr_train[t][i] = tr(train[t][i])\n",
    "        \n",
    "    tr_test = [0]*dig_cnt\n",
    "    for i in range(dig_cnt):\n",
    "        tr_test[i] = tr(test[i])\n",
    "    \n",
    "    return (tr_train, tr_test)\n",
    "\n",
    "def experiment(training_data, test_data, cost_f):\n",
    "    start_time = time.time()\n",
    "\n",
    "    dig_cnt = len(test_data)\n",
    "    test_cnt = len(training_data)\n",
    "    results = np.empty(shape=(dig_cnt, dig_cnt))\n",
    "\n",
    "    for i in range(dig_cnt):\n",
    "        for j in range(dig_cnt):\n",
    "            total_distance = 0\n",
    "            for t in range(test_cnt):\n",
    "                total_distance = total_distance + cost_f(training_data[t][j], test_data[i])            \n",
    "            results[i][j] = total_distance / test_cnt\n",
    "    \n",
    "    print(\"Elapsed time: %s s\" % (time.time() - start_time))\n",
    "\n",
    "    return results \n",
    "\n",
    "def make_table(results):\n",
    "    columns = list(range(len(results)))\n",
    "    df = pd.DataFrame(results, columns)\n",
    "\n",
    "    def is_min(v, x):\n",
    "        minr = np.min(x)\n",
    "        return v <= minr + 1e-6\n",
    "\n",
    "    row_id = [0]\n",
    "    def get_style(x):\n",
    "        minx = np.min(x)\n",
    "        style = []\n",
    "        for i in range(len(x)):\n",
    "            v = x[i]\n",
    "            cell_style = \"\"\n",
    "            if v <= minx + 1e-6:\n",
    "                if i == row_id[0]:\n",
    "                    cell_style = \"background: #B4F8C8\"\n",
    "                else:\n",
    "                    cell_style = \"background: #FFAEBC\"\n",
    "            style.append(cell_style)\n",
    "        row_id[0] = row_id[0] + 1\n",
    "        return style\n",
    "\n",
    "    df = df.style.apply(lambda x: get_style(x), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b883daf0",
   "metadata": {},
   "source": [
    "# Spectrogram\n",
    "\n",
    "Investigate how well we can detect silence by working in the frequency space. By assuming noise is spectrally flat we can compute the variance of frequencies and discard those below a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b101a4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal.windows import hann\n",
    "from math import floor\n",
    "from scipy.fft import fft, rfft, ifft, irfft, fftfreq, rfftfreq\n",
    "\n",
    "def get_frequency_map(samples):\n",
    "    w = get_window()\n",
    "    B = create_overlapping_blocks(samples, w)\n",
    "    [nb, nw] = B.shape\n",
    "\n",
    "    # indices corresponding to the human frequency range\n",
    "    # FIXME: this is coupled w/ the sample rate of 14.4kHz\n",
    "    fi_min = 2\n",
    "    fi_max = 20\n",
    "    M = len(B)\n",
    "    fm = [0]*M\n",
    "    for i in range(M):\n",
    "        xsi = B[i, :]\n",
    "        ysi = fft(xsi)\n",
    "\n",
    "        fm[i] = np.abs(ysi[fi_min:fi_max])\n",
    "    return fm\n",
    "\n",
    "def trim_low_variance(varis):\n",
    "    threshold = 0.01\n",
    "    max_var = np.max(varis)\n",
    "    M = len(varis)\n",
    "    li = 0\n",
    "    while li < M:\n",
    "        if varis[li] > max_var*threshold:\n",
    "            break\n",
    "        li += 1\n",
    "    ri = M - 1\n",
    "    while ri > li:\n",
    "        if varis[ri] > max_var*threshold:\n",
    "            break\n",
    "        ri -= 1\n",
    "    return [li, ri]\n",
    "\n",
    "def detect_silence_spectral(samples):\n",
    "    w = get_window()\n",
    "    fm = get_frequency_map(samples)\n",
    "\n",
    "    varis = [np.var(fs) for fs in fm]\n",
    "    \n",
    "    [li, ri] = trim_low_variance(varis)\n",
    "\n",
    "    step = floor(len(w) * (1 - overlap_pct))\n",
    "    li *= step\n",
    "    ri *= step\n",
    "    return [li, ri + wlen]\n",
    "\n",
    "def spectrogram(samples):\n",
    "    w = get_window()\n",
    "    fm = get_frequency_map(samples)\n",
    "\n",
    "    N = len(fm[0])\n",
    "    M = len(B)\n",
    "    Sxx = np.empty(shape=(N, M))\n",
    "    for i in range(M):\n",
    "        Sxx[:, i] = fm[i]\n",
    "    \n",
    "    plt.figure(1, figsize=(18, 5))\n",
    "    \n",
    "    step = floor(len(w) * (1 - overlap_pct))\n",
    "    xs = np.array(range(M)) * step\n",
    "    plt.pcolormesh(xs, fs, Sxx, shading='gouraud')\n",
    "    \n",
    "    fig, ax = plt.subplots(1, 1, figsize=(18, 3))\n",
    "    marks = detect_silence_spectral(samples)\n",
    "    plot_line(ax, samples, marks)\n",
    "\n",
    "\n",
    "spectrogram(test[2])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb8bf10",
   "metadata": {},
   "source": [
    "# Trimming Silence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19232dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_silence_mov_avg(samples):   \n",
    "    wlen = int(sample_rate / 1000 * window_ms)\n",
    "    \n",
    "    max_amp = np.max(samples)\n",
    "    abs_samples = np.abs(samples)\n",
    "    threshold = 0.02 * max_amp\n",
    "    \n",
    "    wsum = np.sum(abs_samples[0:wlen])\n",
    "    li = 0\n",
    "    # from the left\n",
    "    while li + wlen < len(abs_samples) and wsum / wlen <= threshold:\n",
    "        wsum += abs_samples[li + wlen] - abs_samples[li]\n",
    "        li += 1\n",
    "    \n",
    "    # from the right\n",
    "    wsum = np.sum(abs_samples[-wlen:])\n",
    "    ri = len(abs_samples) - 1 - wlen\n",
    "    while ri > 0 and wsum / wlen <= threshold:\n",
    "        wsum += abs_samples[ri] - abs_samples[ri + wlen]        \n",
    "        ri -= 1\n",
    "        \n",
    "    return [li, ri + wlen]\n",
    "\n",
    "\n",
    "def trim_silence(samples):\n",
    "    samples = nr.reduce_noise(y=samples, sr=sample_rate)\n",
    "    marks = detect_silence_mov_avg(samples)\n",
    "    return samples[marks[0]: marks[1]]\n",
    "    \n",
    "def plot_silence(ax, samples):\n",
    "    samples = nr.reduce_noise(y=samples, sr=sample_rate)\n",
    "    marks = detect_silence_mov_avg(samples)\n",
    "    plot_line(ax, samples, marks)\n",
    "\n",
    "(trimmed_train, trimmed_test) = transform_data(train, test, trim_silence)\n",
    "\n",
    "# Display where we are detecting the silence for some data\n",
    "fig, axs = plt.subplots(10, 3, figsize=(18, 20))\n",
    "for i in range(10):    \n",
    "    plot_silence(axs[i][0], train[0][i])\n",
    "    plot_silence(axs[i][1], train[1][i])    \n",
    "    plot_silence(axs[i][-1], test[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca74a6",
   "metadata": {},
   "source": [
    "# Linear Predictive Coding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8750ffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix_X(x, p):\n",
    "    n = len(x)\n",
    "    # [x_n, ..., x_1, 0, ..., 0]\n",
    "    xz = np.concatenate([x[::-1], np.zeros(p)])\n",
    "    \n",
    "    X = np.zeros((n - 1, p))\n",
    "    for i in range(n - 1):\n",
    "        offset = n - 1 - i \n",
    "        X[i, :] = xz[offset : offset + p]\n",
    "    return X\n",
    "\n",
    "\"\"\"\n",
    "An implementation of LPC.\n",
    "\n",
    "A detailed explanation can be found at\n",
    "https://ccrma.stanford.edu/~hskim08/lpc/\n",
    "\n",
    "x - a vector representing the time-series signal\n",
    "p - the polynomial order of the all-pole filter\n",
    "\n",
    "a - the coefficients to the all-pole filter\n",
    "g - the variance(power) of the source (scalar)\n",
    "e - the full error signal\n",
    "\n",
    "NOTE: This is not the most efficient implementation of LPC.\n",
    "Matlab's own implementation uses FFT to via the auto-correlation method\n",
    "which is noticeably faster. (O(n log(n)) vs O(n^2))\n",
    "\"\"\"\n",
    "def solve_lpc(x, p, ii):\n",
    "    b = x[1:].T\n",
    "        \n",
    "    X = make_matrix_X(x, p)\n",
    "    \n",
    "    a = np.linalg.lstsq(X, b)[0]\n",
    "\n",
    "    e = b.T - np.dot(X, a)\n",
    "    g = np.var(e)\n",
    "\n",
    "    return [a, g]\n",
    "\n",
    "\"\"\"\n",
    "Encodes the input signal into lpc coefficients using 50% OLA\n",
    "\n",
    "x - single channel input signal\n",
    "p - lpc order\n",
    "nw - window length\n",
    " \n",
    "A - the coefficients\n",
    "G - the signal power\n",
    "E - the full source (error) signal\n",
    "\"\"\"\n",
    "def lpc_encode(x, p, w):\n",
    "    B = create_overlapping_blocks(x, w)\n",
    "    \n",
    "    [nb, nw] = B.shape\n",
    "\n",
    "    A = np.zeros((p, nb))\n",
    "    G = np.zeros((1, nb))\n",
    "\n",
    "    for i in range(nb):\n",
    "        [a, g] = solve_lpc(B[i, :], p, i)\n",
    "   \n",
    "        A[:, i] = a\n",
    "        G[:, i] = g\n",
    "    \n",
    "    return [A, G]\n",
    "\n",
    "# Turns multi-series into single series w/ multi y-value\n",
    "def convert_series(series_set):\n",
    "    series_cnt = len(series_set)\n",
    "    series_len = len(series_set[0])\n",
    "    single_series = []\n",
    "    for t in range(series_len):\n",
    "        ys = np.empty(shape=series_cnt)\n",
    "        for i in range(series_cnt):\n",
    "            ys[i] = series_set[i][t]\n",
    "        single_series.append(ys)\n",
    "    return single_series\n",
    "\n",
    "def get_lpc_coeff(samples):\n",
    "    sym = False # periodic\n",
    "    w = hann(floor(0.03*sample_rate), sym) \n",
    "    p = 6 # number of poles\n",
    "    [A, G] = lpc_encode(samples, p, w)\n",
    "    return A\n",
    "\n",
    "def get_as_lpc(samples):\n",
    "    return convert_series(get_lpc_coeff(samples))\n",
    "\n",
    "(lpc_coeff_train, lpc_coeff_test) = transform_data(trimmed_train, trimmed_test, get_as_lpc)\n",
    "    \n",
    "\n",
    "def lpc_heatmap(ax, data):\n",
    "    ax.imshow(get_lpc_coeff(data), aspect='auto')\n",
    "\n",
    "fig, axs = plt.subplots(dig_cnt, 3, figsize=(18, 25))    \n",
    "for i in range(dig_cnt):\n",
    "    lpc_heatmap(axs[i][0], trimmed_train[0][i])\n",
    "    lpc_heatmap(axs[i][1], trimmed_train[1][i])\n",
    "    lpc_heatmap(axs[i][2], trimmed_test[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d0dd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTW over LPC coefficients\n",
    "def fastdtw_cost(s1, s2):\n",
    "    cost, path_ = fastdtw(s1, s2)\n",
    "    return cost\n",
    "\n",
    "results = experiment(lpc_coeff_data, lpc_coeff_test, fastdtw_cost)\n",
    "df = make_table(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5408165a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct DTW (no processing)\n",
    "start_time = time.time()\n",
    "\n",
    "def fastdtw_cost(s1, s2):\n",
    "    return fastdtw(s1, s2)[0]\n",
    "\n",
    "results = experiment(data, test, fastdtw_cost)\n",
    "df = make_table(results)\n",
    "\n",
    "print(\"Elapsed time: %s s\" % (time.time() - start_time))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf51472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTW after silence removal\n",
    "\n",
    "def fastdtw_cost(s1, s2):\n",
    "    cost, path_ = fastdtw(s1, s2)\n",
    "    return cost\n",
    "\n",
    "results = experiment(trimmed_train, trimmed_test, fastdtw_cost)\n",
    "df = make_table(results)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faedf43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
